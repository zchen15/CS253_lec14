{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hqin/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hqin/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe93f124128>\n",
      "(None, 28, 28, 40)\n",
      "<keras.layers.core.Activation object at 0x7fe9085144a8>\n",
      "(None, 28, 28, 40)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fe9085146d8>\n",
      "(None, 14, 14, 40)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe908514b38>\n",
      "(None, 14, 14, 160)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fe907cd6898>\n",
      "(None, 7, 7, 160)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe907cb97f0>\n",
      "(None, 5, 5, 512)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fe907c8a438>\n",
      "(None, 2, 2, 512)\n",
      "<keras.layers.core.Flatten object at 0x7fe907cd6860>\n",
      "(None, 2048)\n",
      "<keras.layers.core.Dense object at 0x7fe907c8a400>\n",
      "(None, 90)\n",
      "<keras.layers.core.Dropout object at 0x7fe907c24898>\n",
      "(None, 90)\n",
      "<keras.layers.core.Dense object at 0x7fe907c3e5c0>\n",
      "(None, 90)\n",
      "<keras.layers.core.Dropout object at 0x7fe907c3e630>\n",
      "(None, 90)\n",
      "<keras.layers.core.Dense object at 0x7fe941e96748>\n",
      "(None, 90)\n",
      "<keras.layers.core.Dropout object at 0x7fe9840a7d68>\n",
      "(None, 90)\n",
      "<keras.layers.core.Activation object at 0x7fe907bd56d8>\n",
      "(None, 90)\n",
      "<keras.layers.core.Dense object at 0x7fe907c24be0>\n",
      "(None, 10)\n",
      "<keras.layers.core.Activation object at 0x7fe907bbaba8>\n",
      "(None, 10)\n",
      "number of params\n",
      "997652\n",
      "WARNING:tensorflow:From /home/hqin/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.1985 - acc: 0.9400 - val_loss: 0.0356 - val_acc: 0.9900\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0623 - acc: 0.9838 - val_loss: 0.0329 - val_acc: 0.9904\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0433 - acc: 0.9887 - val_loss: 0.0352 - val_acc: 0.9914\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0345 - acc: 0.9914 - val_loss: 0.0335 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0293 - acc: 0.9921 - val_loss: 0.0321 - val_acc: 0.9921\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0240 - acc: 0.9935 - val_loss: 0.0356 - val_acc: 0.9921\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0234 - acc: 0.9941 - val_loss: 0.0353 - val_acc: 0.9914\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0184 - acc: 0.9956 - val_loss: 0.0458 - val_acc: 0.9904\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0165 - acc: 0.9958 - val_loss: 0.0420 - val_acc: 0.9907\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0148 - acc: 0.9958 - val_loss: 0.0379 - val_acc: 0.9929\n",
      "60000/60000 [==============================] - 20s 335us/step\n",
      "10000/10000 [==============================] - 3s 347us/step\n",
      "train error\n",
      "[0.003879894989210523, 0.9988]\n",
      "test error\n",
      "[0.03787913880906321, 0.9929]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "# load MNIST data into Keras format\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# look at the shapes\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "\n",
    "# we'll need to one-hot encode the labels\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test)\n",
    "\n",
    "# don't forget to NORMALIZE\n",
    "x_train = np.divide(x_train, 255)\n",
    "x_test = np.divide(x_test, 255)\n",
    "\n",
    "# we must reshape the X data (add a channel dimension)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\n",
    "x_test = x_test.reshape(tuple(list(x_test.shape) + [1]))\n",
    "\n",
    "# look at the shapes\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(40, (3, 3), padding='same',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2) ))\n",
    "\n",
    "model.add(Conv2D(160, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=3, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=90, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(units=90, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(units=90, activation='relu'  ))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# why don't we take a look at the layers and outputs\n",
    "# note: `None` in the first dimension means it can take any batch_size!\n",
    "for i in range(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    print(layer)\n",
    "    print(layer.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# our model has some # of parameters:\n",
    "model.count_params()\n",
    "print(\"number of params\")\n",
    "print(model.count_params())\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "# note that our model outputs two eval params:\n",
    "# 1. loss (categorical cross-entropy)\n",
    "# 2. accuracy\n",
    "model.metrics_names\n",
    "\n",
    "eval_train = model.evaluate(x=x_train, y=y_train)\n",
    "\n",
    "eval_test = model.evaluate(x=x_test, y=y_test)\n",
    "print(\"train error\")\n",
    "print(eval_train)\n",
    "print(\"test error\")\n",
    "print(eval_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
